{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03. Variables and Gradient Computation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udS5V3ClBo01"
      },
      "source": [
        "# __Importing tensorflow__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeMVO0vhBbfY"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGA4iMUUBxsD"
      },
      "source": [
        "# __Introducing Tensorflow Variables__\n",
        "\n",
        "A TensorFlow variable is the recommended way to represent shared, persistent state your program manipulates.\n",
        "\n",
        "Variables are created and tracked via the `tf.Variable` class. A `tf.Variable` represents a tensor whose value can be changed by running ops on it. Specific ops allow you to read and modify the values of this tensor. Higher level libraries like `tf.keras` use `tf.Variable` to store model parameters.\n",
        "\n",
        "# __Why we need variables?__\n",
        "\n",
        "In a optimization problem, like linear regression, we have parameters that we need to tune, in order to optimize our objective funtion.\n",
        "\n",
        "`tf.Variable` marks the tensor as a **tunable parameter**, so that tensorflow knows that this is the tensor that we need to tune/update/change... in order to optimize our objective.\n",
        "\n",
        "So a variable holds a special importance, as the gradient of the function w.r.t this variable would be computed, and later updated using gradient descent.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTSistaACNEe"
      },
      "source": [
        "## __Creating a variable__\n",
        "\n",
        "Any tensor can be converted to a variable by just wrapping it in `tf.Variable`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUM3JFBwBqaQ",
        "outputId": "4a1d3513-a1d0-4e3f-9409-efdf02b2a08d"
      },
      "source": [
        "a_constant_tensor = tf.random.normal([4, 4])\n",
        "a_variable = tf.Variable(a_constant_tensor)\n",
        "\n",
        "print(a_constant_tensor)\n",
        "print('\\n', a_variable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.1685639   0.43453616  0.7295714   1.4290098 ]\n",
            " [ 0.43067005 -0.77764016 -1.041164    0.05287381]\n",
            " [-0.6257793   0.13404195 -0.13665919 -1.2711952 ]\n",
            " [ 0.9694465   0.2251089  -0.33621752 -0.60028934]], shape=(4, 4), dtype=float32)\n",
            "\n",
            " <tf.Variable 'Variable:0' shape=(4, 4) dtype=float32, numpy=\n",
            "array([[ 0.1685639 ,  0.43453616,  0.7295714 ,  1.4290098 ],\n",
            "       [ 0.43067005, -0.77764016, -1.041164  ,  0.05287381],\n",
            "       [-0.6257793 ,  0.13404195, -0.13665919, -1.2711952 ],\n",
            "       [ 0.9694465 ,  0.2251089 , -0.33621752, -0.60028934]],\n",
            "      dtype=float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT1ZAqBFCgsG",
        "outputId": "00115a6f-2bf9-4aad-963c-edaa7f8aeb67"
      },
      "source": [
        "print(\"Name: \", a_variable.name) # each variable created in tensorflow has its unique name.\n",
        "print(\"Shape: \", a_variable.shape)\n",
        "print(\"DType: \", a_variable.dtype)\n",
        "print(\"As NumPy: \", a_variable.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name:  Variable:0\n",
            "Shape:  (4, 4)\n",
            "DType:  <dtype: 'float32'>\n",
            "As NumPy:  [[ 0.1685639   0.43453616  0.7295714   1.4290098 ]\n",
            " [ 0.43067005 -0.77764016 -1.041164    0.05287381]\n",
            " [-0.6257793   0.13404195 -0.13665919 -1.2711952 ]\n",
            " [ 0.9694465   0.2251089  -0.33621752 -0.60028934]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6usffbrEedG"
      },
      "source": [
        "Since a variable is **tunable** or in other words **trainable**, all the variables are created with the `trainable` attribute as `True` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOr2NBZhD164",
        "outputId": "2c050578-2788-4a2b-ae59-94116d9d8d1c"
      },
      "source": [
        "print('Varible is trainable:', a_variable.trainable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Varible is trainable: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54cFDCqNEux0"
      },
      "source": [
        "Although variables are important for differentiation, some variables will not need to be differentiated. You can turn off gradients for a variable by setting trainable to false at creation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb9Sy83REtf8",
        "outputId": "ddc2c794-e3bf-4e55-a293-6d2e7990a357"
      },
      "source": [
        "step_counter = tf.Variable(1, trainable = False)\n",
        "print(step_counter.trainable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU0ps4XhFN1t"
      },
      "source": [
        "# __Gradient Computation in tensorflow__\n",
        "\n",
        "Automatic differentiation is useful for implementing machine learning algorithms such as backpropagation for training neural networks.\n",
        "\n",
        "Now here you'll see the real use of a trainable variable we talked about above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T2ariYRFUjG",
        "outputId": "f6bc4316-41a6-4a77-f451-74e40429ec1f"
      },
      "source": [
        "def objective_function(x):\n",
        "    return 2 * x\n",
        "\n",
        "x = tf.Variable(3.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y = objective_function(x)\n",
        "\n",
        "# `tape.gradient` computes the gradient, below we are computing the gradient of y wrt x\n",
        "dy_dx = tape.gradient(y, x) # which would be 2 ofc since y is simply 2x ...\n",
        "print(dy_dx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(2.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfocwW0JF9Ye"
      },
      "source": [
        "Lets do a bit more complicated gradient computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n8yXBeeFUfm",
        "outputId": "6079149e-e15c-4369-c1c0-543d55abcf9f"
      },
      "source": [
        "w = tf.Variable(tf.ones((3, 2)), name = 'w') # you can also pass the names during variable initialization\n",
        "b = tf.Variable(tf.ones(2), name = 'b')\n",
        "x = [[1., 2., 3.]]\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "    y = tf.matmul(x, w) + b # shape of y would be [1, 2]\n",
        "\n",
        "    loss = tf.reduce_mean(y**2)\n",
        "\n",
        "dloss_dw_and_b = tape.gradient(loss, [w, b]) # will return a list of gradient of loss wrt both w and b\n",
        "\n",
        "print('Gradient of Loss wrt w:', dloss_dw_and_b[0])\n",
        "print('\\nGradient of Loss wrt b:', dloss_dw_and_b[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient of Loss wrt w: tf.Tensor(\n",
            "[[ 7.0000005  7.0000005]\n",
            " [14.000001  14.000001 ]\n",
            " [21.000002  21.000002 ]], shape=(3, 2), dtype=float32)\n",
            "\n",
            "Gradient of Loss wrt b: tf.Tensor([7.0000005 7.0000005], shape=(2,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J6kS-bGHd1e"
      },
      "source": [
        "You can also get a list of all the variables that are the part of the gradient computation as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0T43s5pFUeK",
        "outputId": "f1964fc7-760b-44db-a76c-99e477363cd9"
      },
      "source": [
        "tape.watched_variables() # returns tuple of trainable variables"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=\n",
              " array([[1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.]], dtype=float32)>,\n",
              " <tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=array([1., 1.], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfc72PmJIE4R"
      },
      "source": [
        "Above is the basic introduction to the automatic differentiation in tensorflow, which is enough for basic Neural Network implementations.\n",
        "\n",
        "`tf.GradientTape` is actually extremely powerful, to know other usage and its functionality chekout [this link](https://www.tensorflow.org/guide/autodiff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3fwEhkdmetW"
      },
      "source": [
        "# __Your Assignment__\n",
        "\n",
        "Below are some questions that you need to ans by completing the code. The desired output is written on top of each cell. You need to come up with a code that results to that output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RpsM2Nhmhl-"
      },
      "source": [
        "## __Question 1__\n",
        "You need to create a variable of shape [5, 4],  that is filled with 0.152, and having name as `I love machine learning... its super sexy baby`\n",
        "\n",
        "### __[ Expected Outputs ]__\n",
        "```\n",
        "<tf.Variable 'I love machine learning... its super sexy baby:0' shape=(4, 5) dtype=float32, numpy=\n",
        "array([[0.152, 0.152, 0.152, 0.152, 0.152],\n",
        "       [0.152, 0.152, 0.152, 0.152, 0.152],\n",
        "       [0.152, 0.152, 0.152, 0.152, 0.152],\n",
        "       [0.152, 0.152, 0.152, 0.152, 0.152]], dtype=float32)>\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvjOFIhymfEf",
        "outputId": "e34c8c1c-f773-4030-e9a5-6bddb41d662b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# [========== Your answer below ==========]\n",
        "\n",
        "a = tf.Variable(tf.fill([5,4],0.152), name = \"I love machine learning... its super sexy baby\")\n",
        "a\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'I love machine learning... its super sexy baby:0' shape=(5, 4) dtype=float32, numpy=\n",
              "array([[0.152, 0.152, 0.152, 0.152],\n",
              "       [0.152, 0.152, 0.152, 0.152],\n",
              "       [0.152, 0.152, 0.152, 0.152],\n",
              "       [0.152, 0.152, 0.152, 0.152],\n",
              "       [0.152, 0.152, 0.152, 0.152]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikmRiII9oNDi"
      },
      "source": [
        "## __Question 2__\n",
        "You need to create a functions that computes the mean of all the elements in a tensor multiplied by 5.258\n",
        "\n",
        "Then compute and print the gradients of that function wrt a variable of shape [4, 4] filled with ones.\n",
        "\n",
        "### __[ Expected Outputs ]__\n",
        "```\n",
        "tf.Tensor(\n",
        "[[0.2629 0.2629 0.2629 0.2629 0.2629]\n",
        " [0.2629 0.2629 0.2629 0.2629 0.2629]\n",
        " [0.2629 0.2629 0.2629 0.2629 0.2629]\n",
        " [0.2629 0.2629 0.2629 0.2629 0.2629]], shape=(4, 5), dtype=float32)\n",
        " ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-BJmaIooMEo",
        "outputId": "d8e48139-5ec1-4dd0-f551-0cc42ba10194",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# [========== Your answer below ==========]\n",
        "\n",
        "def function(tensor):\n",
        "    return tf.reduce_mean(tensor*5.258)\n",
        "variable = tf.Variable(tf.ones([4,5]))\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y = function(variable)\n",
        "# print gradients of the function wrt variable\n",
        "dy_dx = tape.gradient(y,variable)\n",
        "dy_dx"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
              "array([[0.2629, 0.2629, 0.2629, 0.2629, 0.2629],\n",
              "       [0.2629, 0.2629, 0.2629, 0.2629, 0.2629],\n",
              "       [0.2629, 0.2629, 0.2629, 0.2629, 0.2629],\n",
              "       [0.2629, 0.2629, 0.2629, 0.2629, 0.2629]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN8fj2GJpmTY"
      },
      "source": [
        "## __Question 3__\n",
        "You need to create a functions that take two tensors as arguments, and returns the their muliplication. \n",
        "\n",
        "Then compute and print the gradients of that function wrt both the variables of shape [2, 2], one filled with 1 and another with 2.5. Both of dtype float32.\n",
        "\n",
        "Also 😛, print out all the variables that are used to compute the value of the function using `tape`.\n",
        "\n",
        "**HINT: use `tape.watc....` :)**\n",
        "\n",
        "### __[ Expected Outputs ]__\n",
        "```\n",
        "Gradients\n",
        " [<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
        "array([[2.5, 2.5],\n",
        "       [2.5, 2.5]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
        "array([[1., 1.],\n",
        "       [1., 1.]], dtype=float32)>]\n",
        "\n",
        "Variables used to compute this function\n",
        " (<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
        "array([[1., 1.],\n",
        "       [1., 1.]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
        "array([[2.5, 2.5],\n",
        "       [2.5, 2.5]], dtype=float32)>)\n",
        " ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZa-igubpmF9",
        "outputId": "ad9b112f-9fc3-4d60-95bd-f3c577141f5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# [========== Your answer below ==========]\n",
        "\n",
        "def function(a, b):\n",
        "    return a*b\n",
        "\n",
        "a = tf.Variable(tf.ones([2,2]),dtype=tf.float32)\n",
        "b = tf.Variable(tf.fill([2,2],2.5),dtype=tf.float32)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y = function(a,b)\n",
        "\n",
        "dy_da_and_b = tape.gradient(y,[a,b])\n",
        "\n",
        "print('Gradients\\n', dy_da_and_b)\n",
        "print('\\nVariables used to compute this function')\n",
        "# here print variables used to compute this function\n",
        "tape.watched_variables()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradients\n",
            " [<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
            "array([[2.5, 2.5],\n",
            "       [2.5, 2.5]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
            "array([[1., 1.],\n",
            "       [1., 1.]], dtype=float32)>]\n",
            "\n",
            "Variables used to compute this function\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
              " array([[1., 1.],\n",
              "        [1., 1.]], dtype=float32)>,\n",
              " <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
              " array([[2.5, 2.5],\n",
              "        [2.5, 2.5]], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q16NgaP-rOLa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}